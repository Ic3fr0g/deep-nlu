{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yelp-review-classification-bert.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhugopinathan/deep-nlu/blob/master/yelp_review_classification_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmLzCtcE9NJl",
        "colab_type": "text"
      },
      "source": [
        "# Predict Yelp Review Ratings (1 star - 5 star)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Change Runtime Type to GPU**\n",
        "\n",
        "---\n",
        "\n",
        "* Model: BERT uncased (fine tuned)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbEYhEErBMqe",
        "colab_type": "text"
      },
      "source": [
        "## Initialize model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQoD8CbI843E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "3057ac61-2984-4978-e65b-2941783d7e56"
      },
      "source": [
        "!wget https://www.dropbox.com/s/kwyyirozli33p2e/yelp-bert-model.tar.gz?dl=0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-23 10:17:19--  https://www.dropbox.com/s/kwyyirozli33p2e/yelp-bert-model.tar.gz?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/kwyyirozli33p2e/yelp-bert-model.tar.gz [following]\n",
            "--2019-08-23 10:17:19--  https://www.dropbox.com/s/raw/kwyyirozli33p2e/yelp-bert-model.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc49e2fb1809b99097311c06cec1.dl.dropboxusercontent.com/cd/0/inline/AnJhBGN5szRjXmPBPYBzadqnirn9ku5oMNkxEdlfJfc7H1jhmM1LUZSXSJyu3R2klGFyelkPA0J46ZSSR3Wor8-V1DEbSbPd-WRO_gQfjv4VMwV7ukkhfRZo18XMTVzYNW4/file# [following]\n",
            "--2019-08-23 10:17:19--  https://uc49e2fb1809b99097311c06cec1.dl.dropboxusercontent.com/cd/0/inline/AnJhBGN5szRjXmPBPYBzadqnirn9ku5oMNkxEdlfJfc7H1jhmM1LUZSXSJyu3R2klGFyelkPA0J46ZSSR3Wor8-V1DEbSbPd-WRO_gQfjv4VMwV7ukkhfRZo18XMTVzYNW4/file\n",
            "Resolving uc49e2fb1809b99097311c06cec1.dl.dropboxusercontent.com (uc49e2fb1809b99097311c06cec1.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
            "Connecting to uc49e2fb1809b99097311c06cec1.dl.dropboxusercontent.com (uc49e2fb1809b99097311c06cec1.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AnLNDT5GjVzRBaDlH_Arq7DO_A3jFZw0bVKk4Txx5Ydo1A2nLgvxZvanT60F1hCnEfZPjDXfq_0Cbte2LLTWvouEexoInbA0eEX9ByvTTs5EAE0NyZPMBKGHqIvaFbdnmAJDxdXiLqnwvZdLcjHFrMrlfOtxu_HSEirPklEhFLKnRlniY53IWuZzm7VikxlZy8yWe-CBI_M2HVT5qEkLvks2_OXAlia0_hdNsmwc9q2xDqtrzPE3ZP_7Zjd5LpUAjK5wOFDZcX-ar4Kaqu9gjQwXTK2qed3mLSCt9-SsupO86QUwB0gPFehKlSGnMwEisc88KHp1X9OjA0O43kueB-zMpd7jY_6sX05mEA7cbAG9xg/file [following]\n",
            "--2019-08-23 10:17:20--  https://uc49e2fb1809b99097311c06cec1.dl.dropboxusercontent.com/cd/0/inline2/AnLNDT5GjVzRBaDlH_Arq7DO_A3jFZw0bVKk4Txx5Ydo1A2nLgvxZvanT60F1hCnEfZPjDXfq_0Cbte2LLTWvouEexoInbA0eEX9ByvTTs5EAE0NyZPMBKGHqIvaFbdnmAJDxdXiLqnwvZdLcjHFrMrlfOtxu_HSEirPklEhFLKnRlniY53IWuZzm7VikxlZy8yWe-CBI_M2HVT5qEkLvks2_OXAlia0_hdNsmwc9q2xDqtrzPE3ZP_7Zjd5LpUAjK5wOFDZcX-ar4Kaqu9gjQwXTK2qed3mLSCt9-SsupO86QUwB0gPFehKlSGnMwEisc88KHp1X9OjA0O43kueB-zMpd7jY_6sX05mEA7cbAG9xg/file\n",
            "Reusing existing connection to uc49e2fb1809b99097311c06cec1.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405603312 (387M) [application/octet-stream]\n",
            "Saving to: ‘yelp-bert-model.tar.gz?dl=0’\n",
            "\n",
            "yelp-bert-model.tar 100%[===================>] 386.81M  43.6MB/s    in 8.2s    \n",
            "\n",
            "2019-08-23 10:17:29 (47.4 MB/s) - ‘yelp-bert-model.tar.gz?dl=0’ saved [405603312/405603312]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PfZFGfE89N_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cf7761a5-af97-4d3c-ea2c-7054ed81fb69"
      },
      "source": [
        "!tar xvfz yelp-bert-model.tar.gz?dl=0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yelp-bert-model/\n",
            "yelp-bert-model/config.json\n",
            "yelp-bert-model/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvmfrzM89eKW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "ecfb53ee-65af-4335-a34a-857e9802dbf4"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 6.5MB/s \n",
            "\u001b[?25hCollecting regex (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Collecting sentencepiece (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 39.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.205)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.6.16)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.205 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.205)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch-transformers) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch-transformers) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.205->boto3->pytorch-transformers) (1.12.0)\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609225 sha256=08aedaff19c084cd57d86f4d92976be902fea2a8b7e847a5e5b291d6018c60e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, sentencepiece, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.1.0 regex-2019.8.19 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30SXiRPpC72B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "de83f206-8745-452a-88bb-aaf0071f507a"
      },
      "source": [
        "!wget https://s3.amazonaws.com/fast-ai-nlp/yelp_review_full_csv.tgz"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-23 10:36:50--  https://s3.amazonaws.com/fast-ai-nlp/yelp_review_full_csv.tgz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.237.61\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.237.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 196146755 (187M) [application/x-tar]\n",
            "Saving to: ‘yelp_review_full_csv.tgz’\n",
            "\n",
            "yelp_review_full_cs 100%[===================>] 187.06M  11.1MB/s    in 23s     \n",
            "\n",
            "2019-08-23 10:37:13 (8.31 MB/s) - ‘yelp_review_full_csv.tgz’ saved [196146755/196146755]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTjyZf-YDeyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ba3d29f4-f461-48ca-d25f-d3fc36c17323"
      },
      "source": [
        "!tar xvfz yelp_review_full_csv.tgz"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "yelp_review_full_csv/\n",
            "yelp_review_full_csv/train.csv\n",
            "yelp_review_full_csv/readme.txt\n",
            "yelp_review_full_csv/test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_QXqVjcF97h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "616738f5-e7b6-4ac2-8e5f-d797c8a27552"
      },
      "source": [
        "!pip install -U vaderSentiment"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 13.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpRVgCoN-9ON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import BertForSequenceClassification, BertTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXKvspQ90PQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8f799bc-a34d-4dde-ff11-de3086acc2cd"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"yelp-bert-model\", \n",
        "                                                      num_labels=5)\n",
        "model.cuda()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLdKowWOIurD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9749dc76-6d54-4592-8882-9043e2ec247e"
      },
      "source": [
        "pretrained_weights = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 929545.13B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WureS9ydCKiJ",
        "colab_type": "text"
      },
      "source": [
        "## Review Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID2SleUe-6GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_features(df, tokenizer, max_seq_length=256):\n",
        "    features = {'all_token_ids' : [],\n",
        "                'all_input_mask' : [],\n",
        "                'all_segment_ids' : [],\n",
        "                'all_label_ids' : []}\n",
        "    \n",
        "    for row in df.itertuples():\n",
        "        # tokenize + index tokens\n",
        "        if hasattr(row,'bert_tokens'):\n",
        "            token_ids = row.bert_tokens\n",
        "        else:\n",
        "            token_ids = tokenizer.encode(row.review)\n",
        "            \n",
        "        if len(token_ids) > max_seq_length-2:\n",
        "            desired_length = max_seq_length-2\n",
        "            # one fourth of the tokens from the head\n",
        "            head_len = int(desired_length/4)\n",
        "            # remaining three fourth from the tail\n",
        "            tail_len = int(3*desired_length/4)\n",
        "            token_ids = token_ids[:head_len] + token_ids[-tail_len:]\n",
        "        token_ids = tokenizer.encode(tokenizer.cls_token) + \\\n",
        "                    token_ids + \\\n",
        "                    tokenizer.encode(tokenizer.sep_token)\n",
        "        input_mask = [1] * len(token_ids)\n",
        "        segment_ids = [0] * len(token_ids)\n",
        "        \n",
        "        # pad upto max_seq_length\n",
        "        padding_length = max_seq_length - len(token_ids)\n",
        "        pad_token_id_list = tokenizer.encode(tokenizer.pad_token)\n",
        "        \n",
        "        token_ids += pad_token_id_list * padding_length\n",
        "        input_mask += pad_token_id_list * padding_length\n",
        "        segment_ids += pad_token_id_list * padding_length\n",
        "        \n",
        "        assert len(token_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        \n",
        "        features['all_token_ids'].append(token_ids)\n",
        "        features['all_input_mask'].append(input_mask)\n",
        "        features['all_segment_ids'].append(segment_ids)\n",
        "        \n",
        "        if hasattr(row,'rating'):\n",
        "            features['all_label_ids'].append(row.rating-1)\n",
        "        \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcK2Wde_HzTN",
        "colab_type": "text"
      },
      "source": [
        "## Rating Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpvD9bJ5H5Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbAkbz5WHux7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiXOizPNH4Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_rating(review):\n",
        "    model.eval()\n",
        "    \n",
        "    one_df = pd.DataFrame(data=[(review,)], columns=['review'])\n",
        "    eval_features = to_features(one_df, tokenizer)\n",
        "    eval_dataset = TensorDataset(torch.tensor(eval_features['all_token_ids']),\n",
        "                        torch.tensor(eval_features['all_input_mask']),\n",
        "                        torch.tensor(eval_features['all_segment_ids']),\n",
        "                       )\n",
        "    batch = eval_dataset.tensors\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs = {'input_ids' : batch[0],\n",
        "              'attention_mask' : batch[1],\n",
        "              'token_type_ids' : batch[2],\n",
        "             }\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]\n",
        "        \n",
        "    preds = logits.detach().cpu().numpy()\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    return preds[0]+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQLYvGv5Cy8P",
        "colab_type": "text"
      },
      "source": [
        "## Load Yelp Reviews (df contains test set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuxcKF0XCFXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwK-kL5CDz1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3myzetDpEFZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.options.display.max_colwidth=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X5wAbzyD5PE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"./yelp_review_full_csv/test.csv\", header=None, names=['rating', 'review'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EIfkMtXFlzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d81HiS5EKyDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_df = df.groupby('rating',group_keys=False).apply(lambda g:g.sample(2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iBdA9csQQbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69fe55da-0985-4b87-ed8a-fc3753acc52e"
      },
      "source": [
        "sample_df"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>compound_score</th>\n",
              "      <th>review_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32328</th>\n",
              "      <td>1</td>\n",
              "      <td>If you are a human being and thus may at some point after midnight need to pee or poop, don't eat here. The restaurant is open until 3 or 4 a.m. and is quite willing to take your money and serve you food and biiiiiiiiig giant sodas, but beware...their restroom closes at midnight. \\n\\nI couldn't believe that as a customer, eating in, I was not allowed to use the restroom. Is that even legal?? \\n\\nI asked where customers were expected to use the restroom after eating and drinking at their establishment. The girl informed me that customers can go \\\"next door to Fat Tuesday\\\". \\nThere are 2 MAJOR issues with that:\\n1 - you can't get into Fat Tuesday (a bar) if you aren't 21, so late night 20 year old sandwich eaters better have big ass bladders.\\n2 - the line to get into Fat Tuesday is sometimes about 20 people long, then once you get carded, get inside, and navigate through the crowd, the bathroom line for the ladies room is another 10-15 long. This means if you leave Jimmy Johns in the middle of eating to pee, you must be 21+ and you will be gone for 20 minutes to an hour to take a leak next door. You can then come back to your crusty sandwich and your annoyed friends who have been babysitting your food while you went pee pee partying over at Tuesdays. Screw that.\\n\\nI'll tell you right now, if I were a guy, I seriously would've pissed on their floor under my table. But...as a girl, that could be messy for me. So...lucky for you Jimmy Johns...I was born without a penis. You win the prize of no pee on your floor, but you will never win my business EVER again.</td>\n",
              "      <td>-0.9585</td>\n",
              "      <td>1582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48344</th>\n",
              "      <td>1</td>\n",
              "      <td>Is it possible to rate an establishment with less than 1 star? The security team here is a joke. I came in with a pocket knife (I am a woman mind you) only to have it confiscated at the door. This wasn't too much to ask as I understand the need for a safe environment. I do want to make it known that I carry my pocket knife everywhere and have never had it confiscated at any of the bars on Fremont. I forgot to get it back that night but came back the next day to grab it. \\n\\nThe only person that was available to talk was the barista that worked the counter at the coffee shop. She informed me that the knife was potbelly locked away in a safe because she couldn't find it. She took down my information and told me she would call once my knife was found. She called me with in a few hours to let me know my knife was there and safe. I was unable to come on Saturday night because I had to work. I came back on Sunday and Monday during the day and found the establishment  closed on both of hose days. Because I work and go to school full time, tonight was the first day I could come back. \\n\\nI was greeted by security and waited for about 15 minutes for the manager to come from upstairs to open the safe that my knife was supposedly kept in. After waiting for the manger for 15 minutes, the manager informs me that there was in fact no knife in the safe. This left me very confused. After gathering my thoughts and confusion, approached the manager with my question about the whereabouts of my pocket knife. After a few minutes the director of security became involved. The director went on to ask me why they would even bother putting someone's knife in safe to begin with. I was just as confused about that as he was. I went on to ask him why several people would tell me that my property was put in a safe and why the where about of my property we're know one day and unknown the next. I also asked his if he was concerned about his employees taking property from customers, specifically weapons. \\n\\nBoth gentlemen were unconcerned with the fact that a weapon was missing and that a customer was very unhappy with losing property at their establishment. Both of these gentlemen need to be taught a few lessons on how to talk and deal with customers. I am very upset and am looking into how I can get this resolved. This security team is very unprofessional in every way possible. I can get past the value of my knife, what's harder to get past is the unclear communication about the situation and the ignorance of the incompetence of their own company and team.</td>\n",
              "      <td>-0.8829</td>\n",
              "      <td>2571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43089</th>\n",
              "      <td>2</td>\n",
              "      <td>Sunday brunch, is just average, nothing special. As for the selection I felt it lacked in variety...basic breakfast foods and flatbread pizzas. (Upstream set the bar high for brunch) the food wasn't cold but  could've been hotter. Previous reviews said the beer was watered down, it must be a theme w/their alcohol selections b/c the Bloody Mary was watered down as we'll, I'm not sure if it's the mix they used...have definitely had better.  The atmosphere is cool and it was packed, but just don't see what all the hype is about.</td>\n",
              "      <td>0.5312</td>\n",
              "      <td>531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38033</th>\n",
              "      <td>2</td>\n",
              "      <td>This location has a much bigger seating area than other locations, which is a big plus in the morning.\\n\\nHowever, their quality control is severely lacking. I love the smokehouse sausage breakfast sandwich but the last one I got  was from here and it was terrible. The sausages tasted uncooked, the egg was about twice the size of the english muffin, and the english muffin itself had been cooked way too long (not burned, but hard).\\n\\nAnother small plus, since theyre bigger, they tend to have more than one box of each flavor of KCup packs available. But if you purchase one, you have to deal w/ their register guy who is really not the brightest bulb in the box. Thats mean, I know, but its unfortunately true. Ive had the same guy 4 times and ive experienced slow service, having my order voided 2-3 times because wrong buttons were pushed, a reply of \\\"Huh?\\\" to every order Ive made....super frustrating.</td>\n",
              "      <td>-0.9491</td>\n",
              "      <td>912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21419</th>\n",
              "      <td>3</td>\n",
              "      <td>After having the ice cream cookie sandwich from next door I felt we needed just a little something else.. so I had a 'like it', sweet and tart ice cream, meh.. its their attempt at the tangy tart fro yo which was mediocre at best. They need to focus on their strengths. However the customer service in here was awesome! 3 adorable and friendly guys who were super eager to help! Such a great change from the usual little bitches behind the counter. I'd come back for sure!</td>\n",
              "      <td>0.9882</td>\n",
              "      <td>472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7434</th>\n",
              "      <td>3</td>\n",
              "      <td>Please hire more help in the evenings and keep black walnut in stock! That's all. Thank you.</td>\n",
              "      <td>0.7955</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42688</th>\n",
              "      <td>4</td>\n",
              "      <td>Lots of food for the money! They are fast and food good...our favorite it the beef chimi and asada fries! Both are huge! Staff is always friendly.</td>\n",
              "      <td>0.8547</td>\n",
              "      <td>146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8947</th>\n",
              "      <td>4</td>\n",
              "      <td>I have been going to Altered Ego for a while now and absolutely love it! I recently moved to CA and still go visit them when I'm in town!\\n\\nLet me first start by saying that I did have one HORRIBLE experience here when I made an appointment for a partial highlight and cut with Kasondra on a whim. My normal gal did not have any available appointments so I decided to test Kasondra out-BAD IDEA. I came in and took the time to explain in detail the type of color and look I wanted. She was very sweet during the process, however when she was finished there was absolutely no difference at all!!! I am naturally a brunette and have always liked to have natural-looking golden blonde highlights. Kasondra gave me no blonde color and my highlights looked brassy and unnatural. On top of that I had asked for a trim of my layers and it literally looked like someone had taken a butcher knife to my hair. It was completely uneven! I went into work the next day and my boss felt so bad for me she allowed me to take 3 hours off to go get my hair fixed!\\n\\nEnter Tawni-the owner of the salon. I called in a panic needing to get my hair fixed as I was leaving town on vacation. The salon offered to put me with Kasondra again but, needless to say, I was not excited about that option. Tawni was AMAZING! She completely fixed Kasondra's botched job on my hair and made my highlights and color look phenomenal! Tawni was also so interactive and engaging the whole time I was in her chair. Her assistant Sonni even gave the most wonderful scalp massage! Since then I will only see Tawni and trust her with my hair! One thing I will say is since she is the owner of the salon and very busy you are often there for a long time with other stylists washing your hair and blowdrying/styling you.\\n\\nI gave this review 4 stars because the salon is so quaint, the staff is lovely, and Tawni is awesome! I will never go back to Kasondra again, but Tawni's service recovery turned a horrible situation into a positive one.</td>\n",
              "      <td>0.9866</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5825</th>\n",
              "      <td>5</td>\n",
              "      <td>I love this pizza</td>\n",
              "      <td>0.6369</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10016</th>\n",
              "      <td>5</td>\n",
              "      <td>In my 8 years living in Las Vegas, I never had a chance to try Spago.  I view it as a bit out of price range, so when their 20 Year Anniversary came up with roll-back pricing, I had to try it.  Went last night with my date, and we asked the assistant GM Drew to pick our food.  Here's what he picked, and my thoughts on each:\\n\\nSignature Roasted Beet Goat Cheese Salad\\nI never would have ordered this but it was delicious.\\n\\nHouse Smoked Sturgeon, Crisp Potato Galette, Horseradish Cream - $12\\nIt was like a spicy latke with fish on top.  Really good.\\n\\n\\n\\\"Chinois Style\\\" Colorado Lamb Chops, Cilantro Mint Vinaigrette, Sweet &amp; Sour Eggplant - $33\\nTender and delicious even without the sauce.  Eggplant was so good my date and I couldn't figure out if it was eggplant!\\n\\nCantonese Style Roasted Duck with Wild Huckleberries, Ginger and Stir-Fried Baby Bok Choy - $20\\nHuge and delicious, and unexpected as we thought we were only getting 1 main course to share.  Needless to say we had plenty of leftovers.\\n\\nEven with the discount I spent a bit more than I had hoped, but everything was delicious and the service was great, as well.  Oh, and they have an amazing bread platter.  Wish I was hungrier and got to try more of that!\\n\\nThanks, Drew W &amp; Scott G!</td>\n",
              "      <td>0.9955</td>\n",
              "      <td>1267</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       rating  ... review_len\n",
              "32328  1       ...  1582     \n",
              "48344  1       ...  2571     \n",
              "43089  2       ...  531      \n",
              "38033  2       ...  912      \n",
              "21419  3       ...  472      \n",
              "7434   3       ...  92       \n",
              "42688  4       ...  146      \n",
              "8947   4       ...  2003     \n",
              "5825   5       ...  17       \n",
              "10016  5       ...  1267     \n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "072BX0JpIiCB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "c70ed12a-5dc1-4fe5-b5b9-a0e27ca72b52"
      },
      "source": [
        "for row in sample_df.itertuples():\n",
        "  print(row.Index, row.rating, predict_rating(row.review))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32328 1 1\n",
            "48344 1 1\n",
            "43089 2 2\n",
            "38033 2 2\n",
            "21419 3 4\n",
            "7434 3 5\n",
            "42688 4 4\n",
            "8947 4 4\n",
            "5825 5 5\n",
            "10016 5 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL6hqWSGGfFt",
        "colab_type": "text"
      },
      "source": [
        "## Rule based sentiment analysis (Vader)\n",
        "\n",
        "Typical threshold values:\n",
        "\n",
        "* positive sentiment: compound score >= 0.05\n",
        "* neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
        "* negative sentiment: compound score <= -0.05\n",
        "\n",
        "* The pos, neu, and neg scores are ratios for proportions of text that fall in each category (so these should all add up to be 1... or close to it with float operation). These are the most useful metrics if you want multidimensional measures of sentiment for a given sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTd7x3yuEEDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3mBpUrCGVDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1yVb65uKYa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_compound_score(review):\n",
        "  return analyzer.polarity_scores(review)['compound']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGu1KyVEReSN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "a02036db-a1f3-447f-c542-c5b3e4e35641"
      },
      "source": [
        "for row in sample_df.itertuples():\n",
        "  print(f\"\"\"{row.Index}, {row.rating} => \n",
        "            Model: {predict_rating(row.review)}, Rule: {get_compound_score(row.review)}\"\"\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32328, 1 => \n",
            "            Model: 1, Rule: -0.9585\n",
            "48344, 1 => \n",
            "            Model: 1, Rule: -0.8829\n",
            "43089, 2 => \n",
            "            Model: 2, Rule: 0.5312\n",
            "38033, 2 => \n",
            "            Model: 2, Rule: -0.9491\n",
            "21419, 3 => \n",
            "            Model: 4, Rule: 0.9882\n",
            "7434, 3 => \n",
            "            Model: 5, Rule: 0.7955\n",
            "42688, 4 => \n",
            "            Model: 4, Rule: 0.8547\n",
            "8947, 4 => \n",
            "            Model: 4, Rule: 0.9866\n",
            "5825, 5 => \n",
            "            Model: 5, Rule: 0.6369\n",
            "10016, 5 => \n",
            "            Model: 5, Rule: 0.9955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk0DAGjWMOaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cc4dcb2-cb02-4586-92ec-9da1f704ae28"
      },
      "source": [
        "get_compound_score(df.iloc[28515].review)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8197"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrMirk6VMvAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec4906be-69d0-4c46-ac74-426069fb924e"
      },
      "source": [
        "get_compound_score(df.iloc[24807].review) # 24807"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.5393"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWkLzpM6Gv7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['compound_score'] = df.review.apply(get_compound_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT2kQxPlPr5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['review_len'] = df.review.str.len()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-R_yD_GNYVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "197abe48-2756-4ead-fd28-c17cc4ea4f5c"
      },
      "source": [
        "df.plot.scatter('rating', 'compound_score');"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyUAAAIPCAYAAABt1HF7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6v8B5mLvXqE6Td0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 402,
              "height": 263
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn97Z0DlO5i1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "32eca3cd-ff99-443c-9a22-e59de777d802"
      },
      "source": [
        "df[(df.rating==1) & (df.compound_score >= 0.99)].sort_values('review_len').head(5)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>compound_score</th>\n",
              "      <th>review_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13310</th>\n",
              "      <td>1</td>\n",
              "      <td>Great ambience but the food doesn't cut it.  The only thing that was pod was the free dinner rolls that were buttery and had sea salt on top to offset the sweetness.  \\n\\nGot the $55 ribeye that came luke warm and under seasoned.  By far the worst ribeye I've ever had at a nice steakhouse.  It was full of fat too.\\n\\nThe risotto was horrible.  Sour like something we bad and it came with huge cherry tomatoes, very unrefined.\\n\\nShort rib was delicious, highly recommended.  Scallops were just whatever and the carpaccio was good, savory and worth trying.\\n\\nService was excellent minus out main server.  He didn't do much but the other help was amazing.\\n\\nMonkey bread was recommended so we tried it.  Very very very sweet, too sweet.  I y thing that was good was the banana ice cream but I wouldn't get this of you for like your deserts too sweet.\\n\\nOverall, it was a bad steakhouse.  Skip it</td>\n",
              "      <td>0.9939</td>\n",
              "      <td>898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2127</th>\n",
              "      <td>1</td>\n",
              "      <td>2/2/11- Talk about going downhill! Dunno know if it is a new mgr or what but when I get a roll with my salad and the bottom half is covered in black mold...EEK! \\n\\nThis little stuck-in-the-seventies place is the restaurant at the Belair Golf Course off of Bell Rd. Its really somewhat of a hidden gem though if you're looking for regular ol' American food. Its quiet, has a lovely view of the lake, peaceful, good service and above average food. The breakfast is especially good with the chicken fried steak being my personal favorite. Its actually real steak not some pre-breaded b.s. I like the club sandwich for lunch- generous amounts of meat, fresh lettuce &amp; tomato, hot fries- how can you go wrong? My only reason for not giving it another star would be the decor. Its perfectly fine, I guess. It's clean. Its just so seventies. But, hey, go there to relax with friends, get a drink from the bar and soak up the seventies charm.</td>\n",
              "      <td>0.9945</td>\n",
              "      <td>935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12757</th>\n",
              "      <td>1</td>\n",
              "      <td>Nice hotel, but for the first time I can honestly say the gambling machines are fixed and the MGM experience is a perfect example why I making these accusations. I spent 4 days at the MGM and played both the tables and the machines. I found a great five cent machine that was very exciting to play. Over the course of 4 days I kept going back to the 10 FREE GAMES machine that offers 10 ways of winning . For 3 staight evenings I played this game and played for atleast 20 minutes or a little longer until it gave you a free spin. Regardless of the amount that I won, I always got atleast one free spin, The last night I was there, I tried the same machine and after 2 1/2 hours of playing ,that  machine never gave me that free spin. $270.00 later I called the manager and he took it out of commission and I called the gaming board. Of course nobody has contacted me but I can assure you that Machines in Casinos are FIXED and controlled. What a waste of time and precious money! MGM you should be ashamed!</td>\n",
              "      <td>0.9967</td>\n",
              "      <td>1007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38244</th>\n",
              "      <td>1</td>\n",
              "      <td>Bad Attitude - Well, that about sums it up. I moved out to the north valley in July of last year and thus far have spent $1900 at this shop. On two occasions I have had to deal with attitude from one of the bike mechanics there - big guy with the beard. I took my road bike in today to ask a question and the condescending mechanic only made fun of how old my bike is - yep, it's a vintage 2003 model. Not the best bike in the world but it has been a great ride for 11 years.  He also felt compelled to tell me \\\"you really need a new bike but don't worry it won't make you any faster\\\". Here's the kicker, I did a race last weekend and decided I was going to upgrade before my next one in September. Sorry Bicycle Vibe, I'll be taking the $4K I have for my new purchase elsewhere. \\n\\nWhy do people have to talk down to others? Did that really make him feel better? Not only did he have a chance to make a great sell and win a customer, he had a chance to be nice to another human being. Does it really matter how old your bike is? It would be so cool to have a nice bike shop here up north, without the attitude.</td>\n",
              "      <td>0.9921</td>\n",
              "      <td>1114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25823</th>\n",
              "      <td>1</td>\n",
              "      <td>We went there just because Tony  Bourdain went there and he loved it.  Well Tony you did us dirt!  This place is for people who like to think they are cool and like to be seen being what they think is cool.  We started with a tomato soup that was flat in flavor and tasteless with raw crunchy slices of tomatoes placed in it.  But that was not the worsted of it.  It was served luke warm  with a chunk of brie,, oh but there is more, the rind  was still on eeeuuuu, omg it was gross!  We ordered the big New York steak ... Dont bother talk about false advertising this is more like a  top round of the lowest quality.  It was not edible, you just chew and chew and chew.  If you enjoy beef gum this is the steak for you, but lay in some dental floss cause boy you will need it.  Service was something out of a fast food restaurant hurried and careless.  For us this by far has won the #1 bad meal of the last 5 years.  Up side they sat us in the garden area which was cool temp wise and very pleasant if I had known the best food in the house was in those pots growing besides me not only would I have saved a bucked to cash, but had a better meal.</td>\n",
              "      <td>0.9903</td>\n",
              "      <td>1148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       rating  ... review_len\n",
              "13310  1       ...  898      \n",
              "2127   1       ...  935      \n",
              "12757  1       ...  1007     \n",
              "38244  1       ...  1114     \n",
              "25823  1       ...  1148     \n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8SIMMHvPNk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}